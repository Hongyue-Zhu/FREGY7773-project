{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company, and need to know whether the company\n",
    "is in near-term danger of not being able to repay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API for students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data.\n",
    "\n",
    "- Each example is a row of data corresponding to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The column `Bankrupt` is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The column `Id` is a Company Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date shape:  (4818, 66)\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATA_DIR = \"./Data\"\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    DATA_DIR = \"../resource/asnlib/publicdata/bankruptcy/data\"\n",
    "\n",
    "data_file = \"5th_yr.csv\"\n",
    "data = pd.read_csv( os.path.join(DATA_DIR, \"train\", data_file) )\n",
    "\n",
    "target_attr = \"Bankrupt\"\n",
    "\n",
    "n_samples, n_attrs = data.shape\n",
    "print(\"Date shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-126.39</td>\n",
       "      <td>0.41355</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>1.2395</td>\n",
       "      <td>1.16500</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.85835</td>\n",
       "      <td>0.12322</td>\n",
       "      <td>5.6167</td>\n",
       "      <td>7.4042</td>\n",
       "      <td>164.310</td>\n",
       "      <td>2.2214</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.023834</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.50839</td>\n",
       "      <td>4.2374</td>\n",
       "      <td>22.034</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>-0.027621</td>\n",
       "      <td>3.6579</td>\n",
       "      <td>0.98183</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>1.01850</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>5.7996</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>26.446</td>\n",
       "      <td>13.802</td>\n",
       "      <td>6.4782</td>\n",
       "      <td>0</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.44606</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>1.565</td>\n",
       "      <td>35.766</td>\n",
       "      <td>0.28196</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.88456</td>\n",
       "      <td>1.05260</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>15.049</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>104.730</td>\n",
       "      <td>3.4852</td>\n",
       "      <td>2.6361</td>\n",
       "      <td>0</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.54562</td>\n",
       "      <td>10.68</td>\n",
       "      <td>438.2</td>\n",
       "      <td>0.13649</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>10.853</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.61173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>0.97282</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0157</td>\n",
       "      <td>7.4626</td>\n",
       "      <td>48.756</td>\n",
       "      <td>7.4863</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>-71.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0116</td>\n",
       "      <td>1.29210</td>\n",
       "      <td>0.50288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>3.4819</td>\n",
       "      <td>8.582</td>\n",
       "      <td>114.580</td>\n",
       "      <td>3.1854</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2       X3      X4       X5        X6         X7  \\\n",
       "0   0.025417   0.41769   0.0568  1.1605  -126.39   0.41355   0.025417   \n",
       "1  -0.023834    0.2101  0.50839  4.2374   22.034  0.058412  -0.027621   \n",
       "2   0.030515   0.44606  0.19569   1.565   35.766   0.28196   0.039264   \n",
       "3   0.052318  0.056366  0.54562   10.68    438.2   0.13649   0.058164   \n",
       "4   0.000992   0.49712  0.12316  1.3036  -71.398         0   0.001007   \n",
       "\n",
       "        X8       X9      X10  ...        X57      X58       X59     X60  \\\n",
       "0   1.2395  1.16500  0.51773  ...   0.049094  0.85835   0.12322  5.6167   \n",
       "1   3.6579  0.98183  0.76855  ...  -0.031011  1.01850  0.069047  5.7996   \n",
       "2  0.88456  1.05260  0.39457  ...   0.077337  0.95006   0.25266  15.049   \n",
       "3   10.853  1.02790  0.61173  ...   0.085524  0.97282         0  6.0157   \n",
       "4   1.0116  1.29210  0.50288  ...   0.001974  0.99925  0.019736  3.4819   \n",
       "\n",
       "      X61      X62     X63     X64  Bankrupt    Id  \n",
       "0  7.4042  164.310  2.2214   1.334         0  4510  \n",
       "1  7.7529   26.446  13.802  6.4782         0  3537  \n",
       "2  2.8179  104.730  3.4852  2.6361         0  3920  \n",
       "3  7.4626   48.756  7.4863  1.0602         0  1806  \n",
       "4   8.582  114.580  3.1854   2.742         0  1529  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty *unhelpful* !\n",
    "\n",
    "What are these mysteriously named features ?\n",
    "\n",
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may still be somewhat unhelpful for those of you not used to reading Financial Statements.\n",
    "\n",
    "But that's partially the point of the exercise\n",
    "- You can *still* perform Machine Learning *even if* you are not an expert in the problem domain\n",
    "    - That's what makes this a good interview exercise: you can demonstrate your thought process even if you don't know the exact meaning of the terms\n",
    "- Of course: becoming an expert in the domain *will improve* your ability to create better models\n",
    "    - Feature engineering is easier if you understand the features, their inter-relationships, and the relationship to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a feel for the data\n",
    "- What is the type of each attribute ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4818 non-null   object \n",
      " 1   X2        4818 non-null   object \n",
      " 2   X3        4818 non-null   object \n",
      " 3   X4        4818 non-null   object \n",
      " 4   X5        4818 non-null   object \n",
      " 5   X6        4818 non-null   object \n",
      " 6   X7        4818 non-null   object \n",
      " 7   X8        4818 non-null   object \n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4818 non-null   object \n",
      " 10  X11       4818 non-null   object \n",
      " 11  X12       4818 non-null   object \n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4818 non-null   object \n",
      " 14  X15       4818 non-null   object \n",
      " 15  X16       4818 non-null   object \n",
      " 16  X17       4818 non-null   object \n",
      " 17  X18       4818 non-null   object \n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4818 non-null   object \n",
      " 21  X22       4818 non-null   object \n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4818 non-null   object \n",
      " 24  X25       4818 non-null   object \n",
      " 25  X26       4818 non-null   object \n",
      " 26  X27       4818 non-null   object \n",
      " 27  X28       4818 non-null   object \n",
      " 28  X29       4818 non-null   object \n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4818 non-null   object \n",
      " 32  X33       4818 non-null   object \n",
      " 33  X34       4818 non-null   object \n",
      " 34  X35       4818 non-null   object \n",
      " 35  X36       4818 non-null   object \n",
      " 36  X37       4818 non-null   object \n",
      " 37  X38       4818 non-null   object \n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4818 non-null   object \n",
      " 40  X41       4818 non-null   object \n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4818 non-null   object \n",
      " 45  X46       4818 non-null   object \n",
      " 46  X47       4818 non-null   object \n",
      " 47  X48       4818 non-null   object \n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4818 non-null   object \n",
      " 50  X51       4818 non-null   object \n",
      " 51  X52       4818 non-null   object \n",
      " 52  X53       4818 non-null   object \n",
      " 53  X54       4818 non-null   object \n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4818 non-null   object \n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4818 non-null   object \n",
      " 59  X60       4818 non-null   object \n",
      " 60  X61       4818 non-null   object \n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4818 non-null   object \n",
      " 63  X64       4818 non-null   object \n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float64(16), int64(2), object(48)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be puzzled:\n",
    "- Most attributes are `object` and *not* numeric (`float64`)\n",
    "- But looking at the data via `data.head()` certainly gives the impression that all attributes are numeric\n",
    "\n",
    "Welcome to the world of messy data !  The dataset has represented numbers as strings.\n",
    "- These little unexpected challenges are common in the real-word\n",
    "- Data is rarely perfect and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you might want to first convert all attributes to numeric\n",
    "\n",
    "**Hint**\n",
    "- Look up the Pandas method `to_numeric`\n",
    "    - We suggest you use the option `errors='coerce'`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating your project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your submission on a test dataset that we provide\n",
    "- It has no labels, so **you** can't use it to evaluate your model, but **we** have the labels\n",
    "- We will call this evaluation dataset the \"holdout\" data\n",
    "\n",
    "Let's get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (1092, 65)\n"
     ]
    }
   ],
   "source": [
    "holdout_data = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "print(\"Data shape: \", holdout_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your model on the holdout examples using metrics\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "\n",
    "From our lecture: we may have to make a trade-off between Recall and Precision.\n",
    "\n",
    "Our evaluation of your submission will be partially based on how you made (and described) the trade-off.\n",
    "\n",
    "You may assume that it is 5 times worse to *fail to identify a company that will go bankrupt*\n",
    "than it is to fail to identify a company that won't go bankrupt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your model\n",
    "\n",
    "Time for you to continue the Recipe for Machine Learning on your own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert all attributes to numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data**\n",
    "\n",
    "We will exclude the attribute of Id because the random number does not help us predict the bankruptcy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.loc[:,\"X1\":\"X64\"]\n",
    "y = data.loc[:,\"Bankrupt\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metrics**\n",
    "\n",
    "Before trying different models, we write our functions of evaluation metrics. This evaluation metrics represents the performance of our models and will be used to select our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "\n",
    "# Define the in-sample evaluation metrics\n",
    "def in_sample_scores(train,predict):\n",
    "    accuracy_in_sample = accuracy_score(train, predict)\n",
    "    recall_in_sample = recall_score(train, predict, pos_label=1, average=\"binary\")\n",
    "    precision_in_sample = precision_score(train, predict, pos_label=1, average=\"binary\")\n",
    "\n",
    "    print(\"\\t{m:s} in sample Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format\n",
    "                                                                           (m=name,\n",
    "                                                                            a=accuracy_in_sample,\n",
    "                                                                            r=recall_in_sample,\n",
    "                                                                            p=precision_in_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the out-of-sample evaluation metrics\n",
    "def out_of_sample_scores(test,predict):\n",
    "    accuracy_test = accuracy_score(test, predict)\n",
    "    recall_test = recall_score(test, predict, pos_label=1, average=\"binary\")\n",
    "    precision_test = precision_score(test, predict, pos_label=1, average=\"binary\")\n",
    "\n",
    "    print(\"\\t{m:s} out of sample Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_test,\n",
    "                                                                            r=recall_test,\n",
    "                                                                            p=precision_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "We start with the logistic regression model.\n",
    "\n",
    "We create a model pipeline that fills in all missing values with their median, scales and normalizes the data, and uses logistic regression as classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic in sample Accuracy: 94.0%, Recall 11.7%, Precision 60.0%\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "scaler = StandardScaler()\n",
    "logistic_clf = LogisticRegression(solver =\"liblinear\",random_state=42)\n",
    "name = \"Logistic\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                                 (\"scaler\",scaler),(\"classifier\",logistic_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train,y_train)\n",
    "y_train_predict = model_pipeline.predict(X_train)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train, y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic out of sample Accuracy: 92.9%, Recall 7.7%, Precision 57.1%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Logistic Regression*: The overall accuracy is good, but the recall and precision are not as expected. Possible reason might be the imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deal with the imbalanced data**\n",
    "\n",
    "Over-sampling: We will generate new samples in the class of Bankrupt == 1 which is under-represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression on balanced data**\n",
    "\n",
    "We then try the logistic regression model on the balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic in sample Accuracy: 79.8%, Recall 77.2%, Precision 81.4%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_pipeline.fit(X_train_balanced,y_train_balanced)\n",
    "y_train_balanced_predict = model_pipeline.predict(X_train_balanced)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train_balanced, y_train_balanced_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic out of sample Accuracy: 81.6%, Recall 65.4%, Precision 22.8%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to use the class_weight parameter in the logistic regression function to deal with the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(class_weight='balanced', random_state=42,\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic in sample Accuracy: 82.3%, Recall 76.2%, Precision 22.7%\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "scaler = StandardScaler()\n",
    "logistic_clf = LogisticRegression(solver =\"liblinear\",class_weight=\"balanced\",random_state=42)\n",
    "name = \"Logistic\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                                 (\"scaler\",scaler),(\"classifier\",logistic_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train,y_train)\n",
    "y_train_predict = model_pipeline.predict(X_train)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train, y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic out of sample Accuracy: 81.1%, Recall 65.4%, Precision 22.2%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Logistic Regression on balanced data*: Both balancing methods yield similar results. We will use the former balancing method in the later notebook since it would work on all models consistently. Compared with the model with imbalanced data, both in-sample and out-of-sample recall get much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principal Component Analysis**\n",
    "\n",
    "Now let's try PCA and see if it can improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()), ('pca', PCA(n_components=64))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcab915e340>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of components')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative variance explained')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To explain 80.0 % of Variance, we need 15 component\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Find the best hyperparameter of n_components\n",
    "# Train PCA\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components = X_train_balanced.shape[1])\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                                 (\"scaler\",scaler),(\"pca\", pca)])\n",
    "model_pipeline.fit(X_train_balanced)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot\n",
    "plt.plot(cumsum)\n",
    "plt.xlabel(\"# of components\")\n",
    "plt.ylabel(\"cumulative variance explained\")\n",
    "plt.show()\n",
    "\n",
    "# Pick the proper n_components for given percentage\n",
    "percentage = 0.8\n",
    "cumsum = pd.DataFrame(data = cumsum)\n",
    "n = cumsum.loc[cumsum[0]>=percentage].index[0] + 1\n",
    "print(\"To explain\", percentage*100,\"% of Variance, we need\", n, \"component\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression with PCA on balanced data**\n",
    "\n",
    "We now try the logistic regression with PCA on the balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()), ('pca', PCA(n_components=15)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic in sample Accuracy: 76.6%, Recall 72.5%, Precision 79.0%\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=15)\n",
    "logistic_clf = LogisticRegression(solver =\"liblinear\",random_state=42)\n",
    "name = \"Logistic\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                                 (\"scaler\",scaler),(\"pca\", pca),(\"classifier\",logistic_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train_balanced,y_train_balanced)\n",
    "y_train_balanced_predict = model_pipeline.predict(X_train_balanced)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train_balanced, y_train_balanced_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic out of sample Accuracy: 78.7%, Recall 65.4%, Precision 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Logistic Regression with PCA on balanced data*: The results are slightly worse than that without the PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "Now let's use a different model to check if balanced data and PCA would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth =  4  ,score =  0.9396825396825397\n",
      "For max_depth =  5  ,score =  0.9391941391941392\n",
      "For max_depth =  6  ,score =  0.9409035409035409\n",
      "For max_depth =  7  ,score =  0.936996336996337\n",
      "For max_depth =  8  ,score =  0.9374847374847375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use Cross-validation to tune the hyperparameter of max_depth\n",
    "for i in range (4,9):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=i,random_state=42)\n",
    "    model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",tree_clf)])\n",
    "    cross_val_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5)\n",
    "    print(\"For max_depth = \", i , \" ,score = \",cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we choose max_depth=6 as our hyperparameter.\n",
    "\n",
    "Also, decision tree does not require feature scaling to be performed as it is not sensitive to the variance in the data. We only need to transform the missing data to its median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('classifier',\n",
       "                 DecisionTreeClassifier(max_depth=6, random_state=42))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTree in sample Accuracy: 96.6%, Recall 47.3%, Precision 95.3%\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "tree_clf = DecisionTreeClassifier(max_depth=6,random_state=42)\n",
    "name = \"Tree\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",tree_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train,y_train)\n",
    "y_train_predict = model_pipeline.predict(X_train)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train, y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTree out of sample Accuracy: 93.8%, Recall 32.7%, Precision 63.0%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree*: Both in-sample and out-of-sample accuracy and precision are good. If the recall can get better, this model would be very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree on balanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth =  8  ,score =  0.9376130734256243\n",
      "For max_depth =  9  ,score =  0.9490742908523344\n",
      "For max_depth =  10  ,score =  0.9589736020629751\n",
      "For max_depth =  11  ,score =  0.9676990024429968\n",
      "For max_depth =  12  ,score =  0.9712158150108576\n",
      "For max_depth =  13  ,score =  0.9718669415038003\n",
      "For max_depth =  14  ,score =  0.9747322882736157\n"
     ]
    }
   ],
   "source": [
    "# Use Cross-validation to tune the hyperparameter of max_depth\n",
    "for i in range (8,15):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=i,random_state=42)\n",
    "    model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",tree_clf)])\n",
    "    cross_val_scores = cross_val_score(model_pipeline, X_train_balanced, y_train_balanced, cv=5)\n",
    "    print(\"For max_depth = \", i , \" ,score = \",cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose max_depth=10 as our hyperparameter. Although it does not maximize the validation scores, it prevents over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('classifier',\n",
       "                 DecisionTreeClassifier(max_depth=10, random_state=42))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTree in sample Accuracy: 97.8%, Recall 98.7%, Precision 96.9%\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10,random_state=42)\n",
    "name = \"Tree\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",tree_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train_balanced,y_train_balanced)\n",
    "y_train_balanced_predict = model_pipeline.predict(X_train_balanced)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train_balanced, y_train_balanced_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTree out of sample Accuracy: 90.7%, Recall 50.0%, Precision 38.8%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree on balanced data*: The in-sample scores are almost perfect. The out-of-sample scores are fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree with PCA on balanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('pca', PCA(n_components=15)),\n",
       "                ('classifier',\n",
       "                 DecisionTreeClassifier(max_depth=10, random_state=42))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTree in sample Accuracy: 95.4%, Recall 98.9%, Precision 92.4%\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "pca = PCA(n_components=15)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10,random_state=42)\n",
    "name = \"Tree\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                                 (\"pca\", pca),(\"classifier\",tree_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train_balanced,y_train_balanced)\n",
    "y_train_balanced_predict = model_pipeline.predict(X_train_balanced)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train_balanced, y_train_balanced_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTree out of sample Accuracy: 83.7%, Recall 46.2%, Precision 21.1%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree with PCA on balanced data*: The results are even worse with PCA than that without PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discovery**\n",
    "\n",
    "After comparing the two models on imbalanced/balanced data and with/without PCA, we find that:\n",
    "\n",
    "1. Balanced data improves performance.\n",
    "2. PCA does not help.\n",
    "\n",
    "Thus, we will not use PCA and continue trying new models on balanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine on balanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('classifier', SVC(kernel='linear'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSVM in sample Accuracy: 80.9%, Recall 76.2%, Precision 84.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the pipeline\n",
    "scaler = StandardScaler()\n",
    "svm_clf = SVC(kernel=\"linear\")\n",
    "name = \"SVM\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                                 (\"scaler\",scaler),(\"classifier\",svm_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train_balanced,y_train_balanced)\n",
    "y_train_balanced_predict = model_pipeline.predict(X_train_balanced)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train_balanced, y_train_balanced_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSVM out of sample Accuracy: 83.1%, Recall 65.4%, Precision 24.6%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SVM on balanced data*: The performance is fairly good, slightly better than that of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes on balanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('classifier', GaussianNB())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNB in sample Accuracy: 51.8%, Recall 96.7%, Precision 50.9%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create the pipeline\n",
    "gnb_clf = GaussianNB()\n",
    "name = \"NB\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",gnb_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train_balanced,y_train_balanced)\n",
    "y_train_balanced_predict = model_pipeline.predict(X_train_balanced)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train_balanced, y_train_balanced_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNB out of sample Accuracy: 14.5%, Recall 94.2%, Precision 7.4%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Naive Bayed on balanced data*: Although the recall is particularly high, the other results are poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest on balanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators =  10  ,score =  0.9934878868078176\n",
      "For n_estimators =  25  ,score =  0.9911438823289902\n",
      "For n_estimators =  40  ,score =  0.9915345921552661\n",
      "For n_estimators =  55  ,score =  0.9914044686482084\n",
      "For n_estimators =  70  ,score =  0.9919254716340934\n",
      "For n_estimators =  85  ,score =  0.9914044686482084\n",
      "For n_estimators =  100  ,score =  0.9917951784744844\n",
      "For n_estimators =  115  ,score =  0.9915348466340934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use Cross-validation to tune the hyperparameter of n_estimators\n",
    "for i in range (10,120,15):\n",
    "    forest_clf = RandomForestClassifier(n_estimators=i,random_state=42)\n",
    "    model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",forest_clf)])\n",
    "    cross_val_scores = cross_val_score(model_pipeline, X_train_balanced, y_train_balanced, cv=5)\n",
    "    print(\"For n_estimators = \", i , \" ,score = \",cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation scores do not fluctuate much as we change our hyperparameter of n_estimators. Thus we just stick to the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth =  3  ,score =  0.8200048350977198\n",
      "For max_depth =  4  ,score =  0.8566024531758958\n",
      "For max_depth =  5  ,score =  0.8851240160152007\n",
      "For max_depth =  6  ,score =  0.9092199375678611\n",
      "For max_depth =  7  ,score =  0.9399580958197611\n",
      "For max_depth =  8  ,score =  0.9591029621335505\n",
      "For max_depth =  9  ,score =  0.9708256989685126\n"
     ]
    }
   ],
   "source": [
    "# Use Cross-validation to tune the hyperparameter of max_depth\n",
    "for i in range (3,10):\n",
    "    forest_clf = RandomForestClassifier(max_depth=i,random_state=42)\n",
    "    model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",forest_clf)])\n",
    "    cross_val_scores = cross_val_score(model_pipeline, X_train_balanced, y_train_balanced, cv=5)\n",
    "    print(\"For max_depth = \", i , \" ,score = \",cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed from above that increasing a unit number of max_depth increases the validation score around 2%. However, to avoid overfitting, we choose max_depth=4 as our hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=4, random_state=42))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tforest in sample Accuracy: 86.3%, Recall 83.6%, Precision 88.4%\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "forest_clf = RandomForestClassifier(max_depth=4,random_state=42)\n",
    "name = \"forest\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),(\"classifier\",forest_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train_balanced,y_train_balanced)\n",
    "y_train_balanced_predict = model_pipeline.predict(X_train_balanced)\n",
    "\n",
    "# Compute the in-sample evaluation metrics\n",
    "in_sample_scores(y_train_balanced, y_train_balanced_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tforest out of sample Accuracy: 85.2%, Recall 63.5%, Precision 27.3%\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-sample evaluation metrics\n",
    "y_test_predict = model_pipeline.predict(X_test)\n",
    "out_of_sample_scores(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random Forest on balanced data*: The results are similar to that of SVM. However, the selection of hyperparameters was quite arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose the best model**\n",
    "\n",
    "Our evaluation metrics contains accuracy, recall, and precision. All of them refer to out-of-sample scores.\n",
    "\n",
    "Since our data is highly imbalanced, accuracy is not a proper measure.\n",
    "\n",
    "Recall is the amount of true positives devided by the amount that true states are positive, which in context is the number of companies that being correctly labeled as Bankrupt devided by the total number of companies that truly go bankrupt.\n",
    "\n",
    "Precision if the amount of true positives devided by the amount that the predictions are positive, which in context is the number of companies that being correctly labeled as Bankrupt devided by the total number of companies that being labeled as Bankrupt.\n",
    "\n",
    "Since there is a trade-off between recall and precision, and it is 5 times worse to fail to identify a company that will go bankrupt than it is to fail to identify a company that won't go bankrupt, recall is 5 times important than precision.\n",
    "\n",
    "Based on balanced data and without PCA, we have five models in total. We rank them from worst to best as follows:\n",
    "\n",
    "- No.5 Naive Bayes\n",
    "    - The accuracy and precision are very low, so we rank it as the last.\n",
    "    \n",
    "\n",
    "- No.4 Decision Tree\n",
    "    - The accuracy and precision are about 10% higher than that of top 3 models, but the recall is about 10% lower than that of top 3 models. Since recall is 5 times important than precision, we rank Decision Tree behind the top 3 models.\n",
    "\n",
    "\n",
    "- No.3 Logistic Regression\n",
    "    - All scores are a little lower than that of SVM model, so we rank it as No.3.\n",
    "\n",
    "\n",
    "- No.2 Random Forest\n",
    "    - The scores of Random Forest and SVM are similar. Random Forest's accuracy and precision are slightly better than that of SVM, while SVM's recall is slightly better than that of Random Forest. However, the result of Random Forest is highly depend on the hyperparameters. It is unsure that the parameters we chose for our training data will perform well on the hold_out data, so we rank it behind the SVM model.\n",
    "    \n",
    "\n",
    "- No.1 Support Vector Machine\n",
    "    - The left one as the result of the elimination process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the chosen model to the whole data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('classifier', SVC(kernel='linear'))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance the data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X, y)\n",
    "\n",
    "# Create the pipeline:\n",
    "scaler = StandardScaler()\n",
    "svm_clf = SVC(kernel=\"linear\")\n",
    "name = \"SVM\"\n",
    "model_pipeline = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                                 (\"scaler\",scaler),(\"classifier\",svm_clf)])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_balanced,y_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission guidelines\n",
    "\n",
    "Although your notebook may contain many models (e.g., due to your iterative development)\n",
    "we will only evaluate a single model.\n",
    "So choose one (explain why !) and do the following.\n",
    "\n",
    "- You will implement the body of a subroutine `MyModel`\n",
    "    - That takes as argument a Pandas DataFrame \n",
    "        - Each row is an example on which to predict\n",
    "        - The features of the example are elements of the row\n",
    "    - Performs predictions on each example\n",
    "    - Returns an array or predictions with a one-to-one correspondence with the examples in the test set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your model against the holdout data\n",
    "- By reading the holdout examples `X_hold` (as above)\n",
    "- Calling `y_hold_pred = MyModel(X_hold)` to get the predictions\n",
    "- Comparing the predicted values `y_hold_pred` against the true labels `y_hold` which are known only to the instructors\n",
    "\n",
    "See the following cell as an illustration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_hold = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "# Predict using MyModel\n",
    "y_hold_pred = MyModel(X_hold)\n",
    "\n",
    "# Compute metrics\n",
    "# accuracy\n",
    "accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "# recall_\n",
    "recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "# precision\n",
    "precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_hold,\n",
    "                                                                            r=recall_hold,\n",
    "                                                                            p=precision_hold\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**\n",
    "\n",
    "The holdout data is in the same format as the one we used for training\n",
    "- Except that it has no attribute for the target\n",
    "- So you will need to perform all the transformations on the holdout data\n",
    "    - As you did on the training data\n",
    "    - Including turning the string representation of numbers into actual numeric data types\n",
    "\n",
    "All of this work *must* be performed within the body of the `MyModel` routine you will write\n",
    "\n",
    "We will grade you by comparing the predictions array you create to the answers known to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def MyModel(X):\n",
    "    # It should create an array of predictions; we initialize it to the empty array for convenience\n",
    "    predictions = []\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    \n",
    "    # Convert all attributes to numeric\n",
    "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    \n",
    "    # Remove the attribute of Id\n",
    "    X = X.loc[:,\"X1\":\"X64\"]\n",
    "   \n",
    "    # Use the fitted model to predict on X\n",
    "    predictions = model_pipeline.predict(X)\n",
    "    \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your work: predict and evaluate metrics on *your* test examples\n",
    "\n",
    "Although only the instructors have the correct labels for the holdout dataset, you may want\n",
    "to create your own test dataset on which to evaluate your out of sample metrics.\n",
    "\n",
    "If you choose to do so, you can evaluate your models using the same metrics that the instructors will use.\n",
    "\n",
    "- Test whether your implementation of `MyModel` works\n",
    "- See the metrics  your model produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSVM Accuracy: 79.4%, Recall 71.2%, Precision 21.6%\n"
     ]
    }
   ],
   "source": [
    "name = \"SVM\"\n",
    "y_test_pred = MyModel(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred, pos_label=1, average=\"binary\")\n",
    "precision_test = precision_score(y_test,   y_test_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_test,\n",
    "                                                                            r=recall_test,\n",
    "                                                                            p=precision_test\n",
    "                                                                            )\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
